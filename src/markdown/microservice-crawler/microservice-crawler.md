---
title: '마이크로서비스 관점에서 가전제품 최저가 크롤러 만들기'
description: 'GCP의 이벤트 스트리밍 서비스 Pub/Sub을 중심으로'
date: 2022-12-12T16:38:03+09:00
draft: false
tags: ['microservice', 'GCP']
slug: 'microservice-crawler'
category: 'dev'
---

#### 들어가며

회사에서 두 번째로 맡은 프로젝트는 다나와의 가전제품 최저가 및 스펙 데이터를 주기적으로 저장하는 크롤러를 만드는 일이었다.
백오피스 관리자가 특정 카테고리의 상품군을 수집 요청하면 크롤러가 원천 데이터를 모아들이고, 백오피스 서버가 더 정제된 형태로 원천 데이터를 재수집해가는 흐름을 만드는 것이 팀의 목표였다.

요구사항은 다음과 같았다.

- 한번 크롤링한 상품은 주기적으로 다시 크롤링해 최신 최저가 정보를 누적 저장할 것
- 마이크로 서비스 형태로 제작하여 안정성을 높일 것
- 기존 파이썬 크롤러보다 속도를 향상시킬 것
- 추후 다른 마켓을 크롤링할 수 있음을 염두에 둘 것

최근 팀의 화두가 마이크로서비스 설계를 지향하여 한 명의 개발자가 하나의 서비스를 완결되게 책임지는 것이었으므로, 서비스와 서비스 간의 배치부터 서비스 내의 세밀한 작업 흐름까지 모두 느슨히 연결된 구조로 만들어내고자 하였다. 내가 맡은 크롤러 또한 내부적으로 하나의 역할만 맡는 리소스들이 서로 통신하며 크롤링을 진행하도록 구현되었다.

#### 마이크로서비스?

마이크로서비스의 핵심 키워드는 '기능 분해'라고 할 수 있다. 히나의 코드 베이스, 하나의 서비스로 묶여 있던 모놀리식 아키텍처를 각각의 서비스, 각각의 DB로 분리하여 배치하는 것이 마이크로서비스 아키텍처의 시작이다. 하지만 이건 외견상의 '분해'일 뿐이다. 사상적인 측면에서의 '기능 분해'란, 전체 어플리케이션을 관리 가능한 최소한의 단위로 응집화, 모듈화시키는 것이다. 서비스를 작은 단위로 모듈화시키면 각 팀이 자율적으로 움직이게 되고, 기능 오류나 서비스 과부하의 리스크를 분산할 수 있으며 배포와 확장이 용이해진다. 새로운 기술 도입이 쉬워진다는 장점은 덤으로 들어온다.

물론 마이크로서비스에 장점만 있는 것은 아니다. 하나의 서비스가 실패하더라도 전체 어플리케이션이 여전히 동작하도록 가용성을 유지하는 것, 서비스 간에 복잡하게 오고가는 요청들을 안정적으로 관리하는 것이 개발팀에 있어서 어려운 과제가 될 것이다.

모놀리식 아키텍처에 비해 늘어나는 관리 포인트 부담을 줄이기 위해 우리 팀은 GCP가 제공하는 서비스를 최대한 이용하기로 결정했다. 이번 포스팅에선 마이크로서비스 형태로 크롤러를 구축하면서 어떤 방식으로 구조를 설계했고, 각 포인트마다 어떤 GCP 서비스를 사용했는지 소개하고자 한다.

#### 크롤러 기능 분해하기

크롤러는 다나와 웹사이트의 카테고리 페이지를 분석하는 과정, 각 페이지를 병렬적으로 방문하며 상품 세부 정보를 모아들이는 과정, 수집한 데이터를 DB에 저장하는 과정까지 세 가지로 나뉜다.

그림으로 설명하면 다음과 같다.

![crawler-structure](crawler-structure.png)

구현 시점에서는 각각의 단일 기능 서비스를 세 개의 독립된 코드 베이스로 제작했다.

- `list-crawler`: 다나와 카테고리 페이지를 분석해 해당 카테고리의 총 상품이 몇 개인지, 크롤링할 페이지는 몇 장인지 판단하는 크롤러
- `detail-crawler`: 한 인스턴스 당 하나의 페이지를 맡아 전체 페이지를 병렬 처리하는 크롤러
- `data-saver`: 크롤링 데이터를 DB에 저장하고 DB와 관련된 각종 API를 제공하는 서버

배포는 컨테이너형 어플리케이션 배포 서비스인 GCP Cloud Run을 이용했다. 컨테이너 기반 어플리케이션 배포 서비스인 Cloud Run은 하나의 서비스가 동시에 몇 건의 요청까지 처리하게 할 것인지, 최대로 확장될 인스턴스 갯수를 얼마나 할지를 자유롭게 설정할 수 있다. 그래서 병렬 처리를 최대한 활용해야 하는 `detail-crawler`는 최대 처리 요청 수를 1건으로 줄인 뒤 확장 인스턴스 갯수를 다수로 잡고, DB 커넥션 풀을 적게 소비해야 하는 `data-saver`는 최대 처리 요청 수를 다수로 잡되 확장 인스턴스 갯수를 최소한으로 처리했다.

<div style="display: grid; gap: 1rem; grid-template-columns: repeat(auto-fit, minmax(280px, 1fr)); margin-bottom: 1rem;">
    <div style="text-align: center; font-size: 0.8rem; margin-bottom: 0.8rem;">
        <img alt="detail_crawler" src="detail_crawler.png" />
        <br/>
        <span style="display: inline-block; margin-bottom: 0.4rem;">병렬처리를 위해 최대 요청 수를 줄이고</span>
        <br/>
        <span>최대 인스턴스 수를 증가시킴</span>
    </div>
    <div style="text-align: center; font-size: 0.8rem; margin-bottom: 0.8rem;">
        <img alt="data_saver" src="product_saver.png" />
        <br/>
        <span style="display: inline-block; margin-bottom: 0.4rem;">DB 커넥션 풀을 활용하고자 최대 요청 수를 늘리고</span>
        <br/>
        <span>최대 인스턴스 수를 감소시킴</span>
    </div>
</div>

이 구조의 성공과 실패를 좌우하는 건 '과연 서비스는 서로 어떻게 통신할 것인가?' 라는 질문에 적절한 해답을 제시하는 것이었다. 이를 정하기 위해 수많은 통신 프로토콜을 비교할 수도 있었지만, 거기에 앞서 우리는 '서비스가 서로 직접 통신하게 할 것인가, 공통의 채널을 이용해 통신하게 할 것인가?'를 먼저 결정해야 했다.

Cloud Run은 인스턴스의 CPU 부하가 높아지면 자동으로 인스턴스를 수평 확장하는 기능을 갖추고 있다. 그렇기에 총 페이지가 수 개에서 수십 개가 넘어가는 상품군의 크롤링을 요청할 경우, 상품 세부 정보를 크롤링하는 인스턴스는 N개 이상으로 확장될 것이다. 모든 크롤링이 병렬적으로 이루어지기에 어떤 페이지의 작업이 먼저 끝날지, 어떤 데이터가 빠르게 전송될 것인지 예측할 수 있는 건 아무것도 없다. 이런 상황에서 각 서비스가 직접 소통하는 방식을 취한다면? 데이터가 소실되거나 DB 저장 요청이 한꺼번에 늘어나면서 기록 실패가 발생할 가능성도 커진다. 안정적인 운영을 위해서는 확장된 크롤러가 공통의 채널 혹은 파이프라인으로 데이터를 전송해 DB 저장 서비스가 순차적으로 값을 받아볼 수 있도록 만들어야 한다.

GCP의 Pub/Sub 이벤트 스트리밍 서비스가 이런 상황에서 사용하기에 가장 알맞은 것이었다.

#### GCP Pub/Sub: 이벤트 스트리밍 파이프라인

참조: [Pub/Sub이란 무엇인가요? | Google Cloud](https://cloud.google.com/pubsub/docs/overview?hl=ko)

Pub/Sub을 쉬운 말로 소개하자면 'RabbitMQ에 Kafka를 끼얹은 서비스'라고 볼 수 있다. RabbitMQ와 같이 특정한 topic을 중심으로 producer와 consumer가 비동기적으로 메시지를 주고받는 메시징 미들웨어의 기본 구조를 갖지만, 여기에 Kafka가 지원하는 수평적 확장 기능 또한 추가되어 있다. 서비스와 서비스 사이에 초당 수천 건의 메시지가 오가더라도 자유자재로 확장-축소를 거듭하며 안정적인 메시지 송/수신을 돕는다.

#### 구조 설계

우리의 크롤러 서비스에 Pub/Sub을 적용하며 구조를 구체화 해보자.

![add_pubsub](add_pubsub.png)

다나와에서 '로봇청소기' 카테고리 페이지의 모든 상품을 크롤링한다 가정했을 때, 현재 (2022.12.12) 기준으로 333건 (해외구매, 중고, 렌탈 제외) 의 상품이 검색된다.

![danawa_01](danawa_01.png)

여기서 페이지 당 검색결과를 90개로 맞춰 놓으면 전체 페이지는 4장이 된다.

![danawa_02](danawa_02.png)

해당 페이지의 url을 `list-crawler`에 전달하면, 크롤러는 페이지를 분석해 총 4개의 메시지를 `detail-crawler` 쪽으로 전송한다. 로봇청소기 카테고리 페이지의 1페이지, 2페이지, 3페이지, 4페이지를 각각 크롤링하라고 요청하는 것이다. 그러면 `detail-crawler`는 4개의 인스턴스로 확장되어 각 페이지를 병렬로 처리한다.

이때 Pub/Sub이 4개의 메시지를 스트리밍해주는 징검다리 역할을 해준다. 이것이 없다면 `list-crawler`는 4개의 `detail-crawler`로 병렬 요청을 보낼 수도 없을 뿐더러 4개의 페이지가 순차적으로 모두 처리된 뒤 완료 응답을 받아야만 작업을 끝낼 수 있게 된다. Pub/Sub으로 메시지를 게시하게 되면 모든 요청은 비동기적으로 처리되므로 `list-crawler`는 메시지를 보낸 뒤 응답을 기다리지 않고 자신의 프로세스를 마무리지을 수 있다.

`detail-crawler`가 `data-saver`로 크롤링 데이터를 전송할 때도 마찬가지다. 크롤링된 페이지는 4개에 불과하지만 DB에 저장해야 할 상품은 300개가 훌쩍 넘는다. 이 큰 규모의 데이터가 동시에 http 요청으로 날아간다면, DB도 부하가 심해질 것이고 요청 자체가 유실될 확률도 높다. 이 데이터를 Pub/Sub으로 먼저 넣어줌으로써 데이터를 보존한 채로 DB 저장을 순차적으로 진행하는 것이 좋다.

#### 다음 단계: Cloud Tasks를 이용한 디스패치 속도 제어

하지만 Pub/Sub만으로는 데이터를 안정적으로 흘려보내기 어려울 수 있다. Pub/Sub은 게시된 메시지를 구독자에게 전송할 때 속도의 제한이 없기 때문이다(100밀리초의 지연 시간이 지나면 거의 동시적으로 발송된다). 비동기적으로, 데이터를 보존한 채로 스트리밍하는 것은 좋지만 그 게시 속도가 너무 빠르고 제어가 되지 않는다면 크롤링이나 DB 저장에 오류가 발생할 수 있다.

Cloud Tasks는 Pub/Sub과 유사한 메시지 전달 기능을 갖고 있지만 호출 방식에 근본적 차이가 있다.

> Pub/Sub와 Cloud Tasks의 핵심적인 차이점은 암시적 호출과 명시적 호출에 관한 개념 차이입니다.
>
> Pub/Sub는 이벤트 게시자와 해당 이벤트의 영향을 받는 구독자를 분리합니다. 이는 게시자가 구독자에 대한 정보가 없어도 된다는 뜻입니다. 따라서 Pub/Sub는 메시지 전달 보장을 위한 경우가 아닌 한, 메시지 전달을 제어하는 기능을 게시자에게 제공하지 않습니다. 이러한 방식으로 Pub/Sub는 **암시적** 호출을 지원합니다. 즉 게시자는 이벤트를 게시하여 구독자의 실행을 암시적으로 유도합니다.
>
> 이에 반해 Cloud Tasks는 게시자가 실행에 대한 완전한 제어 기능을 유지하는 **명시적** 호출을 지향합니다. 특히 게시자는 각 메시지가 전달될 엔드포인트를 지정합니다.
>
> 또한 Cloud Tasks는 Pub/Sub 게시자가 이용할 수 없는 다음과 같은 큐 및 태스크 관리 기능을 제공합니다.
>
> 참조: [Cloud Tasks 또는 Pub/Sub 선택 | Google Cloud](https://cloud.google.com/tasks/docs/comp-pub-sub)

Cloud Tasks는 Pub/Sub에서 발생한 메시지를 넘겨 받아 목적지를 향해 명시적 호출을 할 수 있으며, 초당 디스패치 속도(1초에 최대 몇 건까지 메시지를 전달할 것인가) 및 최대 동시 디스패치 수(동시에 최대 몇 건까지 메시지를 처리할 것인가)를 결정할 수 있다. 즉, Pub/Sub에서 수백 건의 크롤링 데이터가 날아오더라도 Cloud Tasks에서 디스패치 용량을 조절하면 `data-saver`는 DB 커넥션이 허용하는 범위 내에서 순차적으로 데이터를 저장할 수 있게 된다.

![cloud_tasks](cloud_tasks.png)

#### 마치며: 2부 예고

정리해놓고 보니 마이크로서비스의 보다 이론적인 배경이 충분히 구조에 녹아들지 못했다는 생각이 든다. 프로세스 간 통신(IPC)과 외부 세계와의 통신 스타일, 신뢰성, 트랜잭셔널 메시지 개념과 보상 트랜잭션 기능 등등의 관점을 더 설명하고 싶었지만 이번 예시가 그 모든 이론을 모두 녹이기엔 부족해 보였다.

2부에서는 GCP로 구성한 인프라를 terraform으로 형상관리하는 내용을 소개해보고자 한다.
